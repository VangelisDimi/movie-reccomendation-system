{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvbOpTo_fF3I"
      },
      "source": [
        "# Netflix data analyzation\n",
        "Ευάγγελος Δημητριάδης\n",
        "1115201700287"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDz5TmHuDrR7"
      },
      "source": [
        "# Initialisation :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brkm_hTvggcX"
      },
      "source": [
        "Give access to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQrpebPcf2Ht"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCv23BsVCWpO"
      },
      "source": [
        "Data file locations (Change to the correct path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMCHnzmhCZLU"
      },
      "outputs": [],
      "source": [
        "netflix_titles = './gdrive/MyDrive/Data/netflix_titles.csv'\n",
        "imdb_ratings = './gdrive/MyDrive/Data/IMDb ratings.csv'\n",
        "imdb_movies = './gdrive/MyDrive/Data/IMDb movies.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axmCJC1JgymB"
      },
      "source": [
        "Scan netflix_titles for missing data.\n",
        "Delete entries with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQKa4oY1hB5f"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "lines = list()\n",
        "\n",
        "with open(netflix_titles, 'r') as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    for row in csvreader:\n",
        "        if all(v for v in row):\n",
        "            lines.append(row)\n",
        "\n",
        "with open(netflix_titles, 'w') as writeFile:\n",
        "    writer = csv.writer(writeFile)\n",
        "    writer.writerows(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSTu6sYllg2i"
      },
      "source": [
        "Clean up IMDb Movies file to avoid errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poaI0vRslhBS"
      },
      "outputs": [],
      "source": [
        "with open(imdb_movies, 'r') as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    for row in csvreader:\n",
        "      for i, x in enumerate(row):\n",
        "                  if len(x)< 1:\n",
        "                          x = row[i] = \"N/A\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJf5bK1KhSrv"
      },
      "source": [
        "# Queries :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFrWfynsGW1v"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTSgT1LtGULM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from dateutil import parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVGdYtTT9dd0"
      },
      "source": [
        "Pandas options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqxFSlUS9fIX"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPr-f5dEhaTi"
      },
      "source": [
        "**1.** Are there more movies or TV shows on netflix?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL0zDAh-hpnp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "num_series=df['type'].value_counts().get('TV Show',0)\n",
        "num_movies=df['type'].value_counts().get('Movie',0)\n",
        "print(\"Series:\",num_series)\n",
        "print(\"Movies:\",num_movies)\n",
        "if(num_series>num_movies):\n",
        "    print(\"There are more TV shows on Netflix\")\n",
        "else:\n",
        "    print(\"There are more movies on Netflix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhvHMn9PHLuW"
      },
      "source": [
        "**2.** Has Netflix invested more on movies or TV shows in the past few years ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHk1pkn6HVSU"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "current_year = now.year\n",
        "recent_years = 3\n",
        "\n",
        "num_series=df[df['release_year']>=current_year-recent_years]['type'].value_counts().get('TV Show',0)\n",
        "num_movies=df[df['release_year']>=current_year-recent_years]['type'].value_counts().get('Movie',0)\n",
        "print(current_year-recent_years,\"-\",current_year)\n",
        "print(\"Series:\",num_series)\n",
        "print(\"Movies:\",num_movies)\n",
        "if(num_series>num_movies):\n",
        "    print(\"Netflix invests more in TV shows\")\n",
        "else:\n",
        "    print(\"Netflix invests more in movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x55anErTHV12"
      },
      "source": [
        "**3.** Country with the most content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBU9NbX4HaQ6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "country = df['country'].value_counts().keys().tolist()[0]\n",
        "titles = df['country'].value_counts().tolist()[0]\n",
        "print(country,\":\",titles,\"titles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMZkRFykQgHp"
      },
      "source": [
        "**4.** Genres produced by each country\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzjxU3iDQlgn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "countries=df['country'].str.split(',', expand=True).stack().unique()\n",
        "countries.sort()\n",
        "countries = list(filter(None, countries))\n",
        "for country in countries:\n",
        "    genres=df[df['country'].str.contains(country)]['listed_in'].str.split(',', expand=True).stack().unique()\n",
        "    genres.sort()\n",
        "    gnr=','.join(genres)\n",
        "    print(country,\":\",gnr,\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmFMZC8nQl1f"
      },
      "source": [
        "**5.** Actors with the most appearances in movies and TV shows for each country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdJyuU9DQyWG"
      },
      "outputs": [],
      "source": [
        "#Movies\n",
        "df = pd.read_csv(netflix_titles)\n",
        "countries=df['country'].str.split(',', expand=True).stack().unique()\n",
        "countries.sort()\n",
        "countries = list(filter(None, countries))\n",
        "for country in countries:\n",
        "    df2=df[df['country'].str.contains(country)]\n",
        "    actors = df2[df2['type']=='Movie']['cast']\n",
        "    appearances = df2[df2['type']=='Movie']['cast']\n",
        "    if(len(actors)==0 or len(appearances)==0):\n",
        "        continue\n",
        "    actors=actors.str.split(',',expand=True).stack().value_counts().keys().tolist()\n",
        "    appearances = appearances.str.split(',',expand=True).stack().value_counts().tolist()\n",
        "\n",
        "    data={'Actor':actors,'No. Appearances':appearances}\n",
        "    ap=pd.DataFrame(data)\n",
        "    ap.index = range(1, len(ap)+1)\n",
        "    print(country)\n",
        "    display(ap[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pchd2eWBg5Er"
      },
      "outputs": [],
      "source": [
        "#TV Shows\n",
        "df = pd.read_csv(netflix_titles)\n",
        "countries=df['country'].str.split(',', expand=True).stack().unique()\n",
        "countries.sort()\n",
        "countries = list(filter(None, countries))\n",
        "for country in countries:\n",
        "    df2=df[df['country'].str.contains(country)]\n",
        "    actors = df2[df2['type']=='TV Show']['cast']\n",
        "    appearances = df2[df2['type']=='TV Show']['cast']\n",
        "    if(len(actors)==0 or len(appearances)==0):\n",
        "        continue\n",
        "    actors=actors.str.split(',',expand=True).stack().value_counts().keys().tolist()\n",
        "    appearances = appearances.str.split(',',expand=True).stack().value_counts().tolist()\n",
        "\n",
        "    data={'Actor':actors,'No. Appearances':appearances}\n",
        "    ap=pd.DataFrame(data)\n",
        "    ap.index = range(1, len(ap)+1)\n",
        "    print(country)\n",
        "    display(ap[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XJJs9oZhBd2"
      },
      "source": [
        "**6.** Distribution of age appropriate content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKJSj5-_hY1Z"
      },
      "outputs": [],
      "source": [
        "#Movies\n",
        "df = pd.read_csv(netflix_titles)\n",
        "counts=df[df['type']=='Movie']['rating'].value_counts()\n",
        "lk=sum([counts.get(k,0) for k in ['G','TV-Y','TV-G']])\n",
        "ok=sum([counts.get(k,0) for k in ['PG','TV-Y7','TV-Y7-FV','TV-PG']])\n",
        "t=sum([counts.get(k,0) for k in ['PG-13','TV-14']])\n",
        "m=sum([counts.get(k,0) for k in ['R','NC-17','TV-MA']])\n",
        "data = [[lk,ok,t,m]]\n",
        "ratings = pd.DataFrame(data, columns = ['Little Kids','Older Kids','Teens','Mature'])\n",
        "ratings.index = ['']\n",
        "print(\"Movies\")\n",
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKVahy3yl_2B"
      },
      "outputs": [],
      "source": [
        "#TV Shows\n",
        "df = pd.read_csv(netflix_titles)\n",
        "counts=df[df['type']=='TV Show']['rating'].value_counts()\n",
        "lk=sum([counts.get(k,0) for k in ['G','TV-Y','TV-G']])\n",
        "ok=sum([counts.get(k,0) for k in ['PG','TV-Y7','TV-Y7-FV','TV-PG']])\n",
        "t=sum([counts.get(k,0) for k in ['PG-13','TV-14']])\n",
        "m=sum([counts.get(k,0) for k in ['R','NC-17','TV-MA']])\n",
        "data = [[lk,ok,t,m]]\n",
        "ratings = pd.DataFrame(data, columns = ['Little Kids','Older Kids','Teens','Mature'])\n",
        "ratings.index = ['']\n",
        "print(\"TV Shows\")\n",
        "ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-C8g85Nl7Sc"
      },
      "source": [
        "**7.** Average Netflix releases per month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDXf9EITrNvV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "years=df['date_added'].tolist()\n",
        "for i in range(len(years)):\n",
        "    years[i]=parser.parse(years[i])\n",
        "    years[i]=years[i].year\n",
        "years = list(set(years))\n",
        "years.sort()\n",
        "\n",
        "months = [\"January\",\"February\",\"March\",\n",
        "          \"April\",\"May\",\"June\",\"July\",\n",
        "          \"August\",\"September\",\"October\",\n",
        "          \"November\",\"December\"]\n",
        "\n",
        "entries={}\n",
        "for month in months:\n",
        "    entries[month] = 0\n",
        "\n",
        "for month in months:\n",
        "    count=df[df['date_added'].str.contains(month)]\n",
        "    entries[month]+=len(count)\n",
        "    entries[month]=entries[month]/len(years)\n",
        "\n",
        "print(years[0],\"-\",years[-1])\n",
        "print(\"Average Netflix releases per month\")\n",
        "avg=pd.DataFrame.from_dict(entries,orient='index')\n",
        "avg.columns = ['Average Releases']\n",
        "avg.index.name = 'Month'\n",
        "avg.plot.bar()\n",
        "avg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHLOeEFPrOFF"
      },
      "source": [
        "**8.** All genres available on netflix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAAlkowqrOQd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "genres=df['listed_in'].str.split(',', expand=True).stack().unique()\n",
        "genres.sort()\n",
        "\n",
        "gnr=pd.DataFrame(genres,columns=[\"Genre\"])\n",
        "gnr=gnr.style.hide_index()\n",
        "gnr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz0mLqdvrOZq"
      },
      "source": [
        "**9.** Directors analyzed by country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofBJ65AjrOwd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "countries=df['country'].str.split(',', expand=True).stack().unique().tolist()\n",
        "countries.sort()\n",
        "countries = list(filter(None, countries))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR49rQJzh4Uq"
      },
      "outputs": [],
      "source": [
        "#Number of directors per country\n",
        "counts = {}\n",
        "for country in countries:\n",
        "    counts[country]=len(df[df['country'].str.contains(country)]['director'].str.split(',', expand=True).stack().unique())\n",
        "dpc=pd.DataFrame.from_dict(counts,orient='index')\n",
        "dpc.columns = ['No. directors']\n",
        "dpc.index.name = 'Country'\n",
        "dpc=dpc.sort_values(by=['No. directors'], ascending=False)\n",
        "dpc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUmcFSTuh6Aq"
      },
      "outputs": [],
      "source": [
        "#Top directors per country (By number of movies)\n",
        "top_dir={}\n",
        "for country in countries:\n",
        "    top_dir[country]=[df[df['country'].str.contains(country)]['director'].str.split(',', expand=True).stack().value_counts().keys().tolist()[0]\n",
        "    ,df[df['country'].str.contains(country)]['director'].str.split(',', expand=True).stack().value_counts().tolist()[0]]\n",
        "tdpc=pd.DataFrame.from_dict(top_dir,orient='index')\n",
        "tdpc.columns = ['Director','No. Ttiles']\n",
        "tdpc.index.name = 'Country'\n",
        "tdpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMX3EnIQrX56"
      },
      "source": [
        "**10.** Series organized by number of seasons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHN5bb45rYEU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "series=df[df['type']==\"TV Show\"]\n",
        "\n",
        "seasons=series['duration'].unique()\n",
        "seasons.sort()\n",
        "\n",
        "entries={}\n",
        "for season in seasons:\n",
        "    entries[season]=[(','.join(series[series['duration']==season]['title'])),len(series[series['duration']==season]['title'])]\n",
        "\n",
        "\n",
        "sps=pd.DataFrame.from_dict(entries,orient='index')\n",
        "sps.columns = ['Series Titles','No. Shows']\n",
        "sps.index=(int(s.split(' ',1)[0]) for s in sps.index)\n",
        "sps=sps.sort_index()\n",
        "sps.index.name = 'No. Seasons'\n",
        "sps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMD0on92rYVj"
      },
      "source": [
        "**11.** Top rated movies on Netflix based on IMDb ratings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S6v8aidrYcV"
      },
      "outputs": [],
      "source": [
        "#11\n",
        "df1 = pd.read_csv(netflix_titles)\n",
        "df1= df1[df1['type']=='Movie']\n",
        "df2 = pd.read_csv(imdb_movies,dtype=object)\n",
        "df3 = pd.read_csv(imdb_ratings)\n",
        "\n",
        "df=df1.merge(df2,how='inner',left_on=['title'],right_on=['title'])\n",
        "df=df.merge(df3,how='inner',left_on=['imdb_title_id'],right_on=['imdb_title_id'])\n",
        "\n",
        "df=df.sort_values(by=['weighted_average_vote'], ascending=False)\n",
        "df=df[['show_id','title','weighted_average_vote']]\n",
        "df.index = range(1, len(df)+1)\n",
        "df[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb0qSxWyhuQO"
      },
      "source": [
        "# Recommendation system :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY8EBXm-k1jl"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0W4U2XFk13M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBej-S87ZL-G"
      },
      "source": [
        "Dataframes used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYQ1LbGhZLH0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(netflix_titles)\n",
        "movies=df[df['type']=='Movie']\n",
        "\n",
        "import warnings\n",
        "from pandas.core.common import SettingWithCopyWarning\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
        "movies['description']=movies['description'].replace('[^a-zA-Z ]','',regex=True).astype(str)#Strip all special characters and digits\n",
        "\n",
        "ids=movies['show_id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1N3nz6WiE0b"
      },
      "source": [
        "### **1.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmbDlJ7TdaCp"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "class LemmaTokenizer(object):\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self,text):#Lemmatize and remove stop_words\n",
        "        return [self.wnl.lemmatize(t) for t in word_tokenize(text) if t not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJXbQREuO4sn"
      },
      "source": [
        "**a**.) Create boolean BoW(Bag of Words) table for unigrams and bigrams of Netflix movie descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyoeAzlO-H_"
      },
      "outputs": [],
      "source": [
        "bow_v = CountVectorizer(ngram_range=(1, 2),binary=True,tokenizer=LemmaTokenizer(),max_df=1.0, min_df=1)\n",
        "bow_x = bow_v.fit_transform(movies['description'])\n",
        "\n",
        "bow_words=bow_v.get_feature_names()\n",
        "bow_list=bow_x.toarray()\n",
        "\n",
        "bow = {}\n",
        "i=0\n",
        "for id in ids:\n",
        "        bow[id] = bow_list[i]\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_p0ITzsO-Qp"
      },
      "source": [
        "b.)Create TF-IDF (Term Frequency - InverseDocument Frequency) table for unigrams and bigrams of Netflix movie descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBO0jhepO_HP"
      },
      "outputs": [],
      "source": [
        "tfidf_v = TfidfVectorizer(ngram_range=(1, 2),tokenizer=LemmaTokenizer(),max_df=1.0, min_df=1)\n",
        "tfidf_x = tfidf_v.fit_transform(movies['description'])\n",
        "\n",
        "tfidf_words=tfidf_v.get_feature_names()\n",
        "tfidf_list=tfidf_x.toarray()\n",
        "\n",
        "tfidf = {}\n",
        "i=0\n",
        "for id in ids:\n",
        "        tfidf[id] = tfidf_list[i]\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn4ORsuwPKsx"
      },
      "source": [
        "### **2.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAJ7Aq4C8fVk"
      },
      "source": [
        "Find similarity between two movies:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wIWA_CoPKsy"
      },
      "source": [
        "a.)Using Jaccard/Tanimoto coefficient on Boolean BoW vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jekTlUjRPKsy"
      },
      "outputs": [],
      "source": [
        "def movies_similarity_bow(id1,id2):\n",
        "    return 1-cdist([bow[id1]],[bow[id2]],metric='jaccard')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE9oWFPbPKsz"
      },
      "source": [
        "b.)Using cosine similarity on TF-IDF vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhYRwapHPKsz"
      },
      "outputs": [],
      "source": [
        "def movies_similarity_tfidf(id1,id2):\n",
        "    return 1-cdist([tfidf[id1]],[tfidf[id2]],metric='cosine')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahFDMwoa71HI"
      },
      "source": [
        "Find the 100 most similar movies for each movie using the two above methods (Boolean BoW Jaccard/Tanimoto\n",
        "coefficient - TF-IDF  cosine similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sytm2ZSD9aax"
      },
      "outputs": [],
      "source": [
        "# Runs slow ,can be sped up by creating a smaller vocabulary\n",
        "# On 1.a and 1.b you can pass max_features=n argument on the vectorizer to achieve that\n",
        "\n",
        "#Top-100 using boolean bow and jaccard\n",
        "similar_bow={}\n",
        "for id in ids:\n",
        "    similar_list=1-cdist([bow[id]],bow_list,metric='jaccard')[0]\n",
        "    similar = {}\n",
        "    i=0\n",
        "    for id in ids:\n",
        "            similar[id] = similar_list[i]\n",
        "            i+=1\n",
        "    del similar[id]\n",
        "    similar=dict(sorted(similar.items(), key=lambda item: item[1], reverse=True)[:100])\n",
        "    similar_bow[id]=similar\n",
        "\n",
        "#Top-100 using tf-idf and cosine\n",
        "similar_tfidf={}\n",
        "for id in ids:\n",
        "    similar_list=1-cdist([tfidf[id]],tfidf_list,metric='cosine')[0]\n",
        "    similar = {}\n",
        "    i=0\n",
        "    for id in ids:\n",
        "            similar[id] = similar_list[i]\n",
        "            i+=1\n",
        "    del similar[id]\n",
        "    similar=dict(sorted(similar.items(), key=lambda item: item[1], reverse=True)[:100])\n",
        "    similar_tfidf[id]=similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjZPMhayPY6w"
      },
      "source": [
        "### **3.** Find n most similar movies for movie with given title using the given method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx8chHxX9Z1g"
      },
      "outputs": [],
      "source": [
        "def get_similar_movies1(title, n, method):\n",
        "    s_id=movies[movies['title']==title]['show_id']\n",
        "    s_id.index = range(0, len(s_id))\n",
        "    s_id=s_id[0]\n",
        "\n",
        "    if method=='boolean':\n",
        "        similar_list=1-cdist([bow[s_id]],bow_list,metric='jaccard')[0]\n",
        "    elif method=='tf-idf':\n",
        "        similar_list=1-cdist([tfidf[s_id]],tfidf_list,metric='cosine')[0]\n",
        "\n",
        "    similar = {}\n",
        "    i=0\n",
        "    for id in ids:\n",
        "            similar[id] = similar_list[i]\n",
        "            i+=1\n",
        "    del similar[s_id]\n",
        "    similar=sorted(similar.items(), key=lambda item: item[1], reverse=True)[:n]\n",
        "\n",
        "    #Create pandas dataframe for results\n",
        "    similar_ids,similarities=zip(*similar)\n",
        "    similar_titles=[None] * len(similar_ids)\n",
        "    i=0\n",
        "    for id in similar_ids:\n",
        "      similar_titles[i]=movies[movies['show_id']==id]['title'].iloc[0]\n",
        "      i+=1\n",
        "    similar_df=pd.DataFrame(\n",
        "    {'show_id': similar_ids,\n",
        "    'title': similar_titles,\n",
        "    'similarity': similarities\n",
        "    })\n",
        "    similar_df.index = range(1, len(similar_df)+1)\n",
        "\n",
        "    return similar_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQGj7ffdy9Mp"
      },
      "source": [
        "Indicative results :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xag4L_kiYrB2"
      },
      "source": [
        "Η boolean μέθοδος δεν λαμβάνει υπόψιν το πόσες φορές εμφανίζεται ένα term στο description(bow),την συχνότητα εμφάνισης(tf), ούτε την σημαντικότητα του term(idf).Μετράει απλά αν μια λέξη βρίσκεται στην πρόταση ή όχι.Έτσι φυσικά είναι λιγότερο ακριβής στον υπολογισμό του similarity από την μέθοδο που χρησιμοποιεί τον tf-idf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xj8Lz8PTVwO"
      },
      "outputs": [],
      "source": [
        "print(\"Django Unchained\")\n",
        "print(\"Boolean method:\")\n",
        "display(get_similar_movies1('Django Unchained', 20, 'boolean'))\n",
        "print(\"TF-IDF method:\")\n",
        "display(get_similar_movies1('Django Unchained', 20, 'tf-idf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-PjrZxQ9h4b"
      },
      "source": [
        "Περιγραφή ταινίας \"Django Unchained\" : Accompanied by a German bounty hunter, a freed slave named Django travels across America to free his wife from a sadistic plantation owner.\n",
        "\n",
        "Οι δύο μέθοδοι έχουν αρκετά παρόμοια αποτελέσματα για την ταινία που δόθηκε(Western και ταινίες δράσης),η boolean μέθοδος βγάζει όμως πιο ανακριβή αποτελέσματα.\n",
        "Έχει πολλές κοινές ταινίες με την tf-idf αλλά έχει χαμηλότερο similarity για ταινίες western και στα κορυφαία αποτελέσματα εμφανίζει την ταινία \"Un plus une\" με την οποία δεν μοιράζονται κάποιο σημαντικό term(μόνο την λέξη travel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr7iCaBIXpqn"
      },
      "outputs": [],
      "source": [
        "print(\"LEGO Marvel Super Heroes: Avengers Reassembled!\")\n",
        "print(\"Boolean method:\")\n",
        "display(get_similar_movies1('LEGO Marvel Super Heroes: Avengers Reassembled!', 20, 'boolean'))\n",
        "print(\"TF-IDF method:\")\n",
        "display(get_similar_movies1('LEGO Marvel Super Heroes: Avengers Reassembled!', 20, 'tf-idf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J10OliTXTqEQ"
      },
      "source": [
        "Περιγραφή ταινίας \"LEGO Marvel Super Heroes: Avengers Reassembled!\" : \"When Ultron seizes control of Iron Man's armor, the Avengers race to save their friend and stop an evil plot to take over the world.\"\n",
        " \n",
        "Στο παραπάνω παράδειγμα η απόκλιση των μεθόδων γίνεται ακόμα πιο εμφανής.Η μέθοδος tf-idf έχει τις ταινίες marvel ως κορυφαίες προτάσεις ενώ η boolean ως χαμηλότερες.Επίσης η boolean ενώ εμφανίζει αρκετές κοινές ταινίες(παιδικές και marvel) εμφανίζει και τελείως άσχετες ταινίες όπως \"Nymphomaniac: Volume 1\",\"30 Days of Luxury\" και \"My Step Dad: The Hippie\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3deyGaQqPb8C"
      },
      "source": [
        "### **4.** Find n most similar movies for given description using the given method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWOJgv_j9ZZx"
      },
      "outputs": [],
      "source": [
        "def get_similar_movies2(description,n,method):\n",
        "    #Create new dataframe for description\n",
        "    title = pd.DataFrame([['search_item',description]],columns=['show_id','description'])\n",
        "    s_id='search_item'\n",
        "    title['description']=title['description'].replace('[^a-zA-Z ]','',regex=True).astype(str)#Strip all special characters and digits\n",
        "\n",
        "    if method=='boolean': #BoW\n",
        "        #Create new feature vector from dataframe\n",
        "        tbow_v = CountVectorizer(ngram_range=(1, 2),binary=True,tokenizer=LemmaTokenizer(),max_df=1.0, min_df=1)\n",
        "        tbow_x = tbow_v.fit_transform(title['description'])\n",
        "        tbow_words=tbow_v.get_feature_names()\n",
        "        ttbow_list=tbow_x.toarray()[0]\n",
        "\n",
        "        #Initialize array to make the comparison\n",
        "        tbow_list = [0] * len(bow_words)\n",
        "        for gram in tbow_words:\n",
        "            if gram in bow_words:\n",
        "                tbow_list[bow_words.index(gram)]=1\n",
        "\n",
        "        #Find similarities between description and movies\n",
        "        similar_list=1-cdist([tbow_list],bow_list,metric='jaccard')[0]\n",
        "    elif method=='tf-idf': #Tf-idf\n",
        "        #Create new feature vector from dataframe\n",
        "        ttfidf_v = TfidfVectorizer(ngram_range=(1, 2),tokenizer=LemmaTokenizer())\n",
        "        ttfidf_x = ttfidf_v.fit_transform(title['description'])\n",
        "        ttfidf_words=ttfidf_v.get_feature_names()\n",
        "        tttfidf_list=ttfidf_x.toarray()[0]\n",
        "\n",
        "        #Initialize array to make the comparison\n",
        "        ttfidf_list = [0] * len(tfidf_words)\n",
        "        i=0\n",
        "        for gram in ttfidf_words:\n",
        "            if gram in tfidf_words:\n",
        "                ttfidf_list[tfidf_words.index(gram)]=tttfidf_list[i]\n",
        "            i+=1\n",
        "            \n",
        "        #Find similarities between description and movies\n",
        "        similar_list=1-cdist([ttfidf_list],tfidf_list,metric='cosine')[0]\n",
        "\n",
        "    #Find n most common movies for given description\n",
        "    similar = {}\n",
        "    i=0\n",
        "    for id in ids:\n",
        "            similar[id] = similar_list[i]\n",
        "            i+=1\n",
        "    similar=sorted(similar.items(), key=lambda item: item[1], reverse=True)[:n]\n",
        "\n",
        "    #Create pandas dataframe for results\n",
        "    similar_ids,similarities=zip(*similar)\n",
        "    similar_titles=[None] * len(similar_ids)\n",
        "    i=0\n",
        "    for id in similar_ids:\n",
        "      similar_titles[i]=movies[movies['show_id']==id]['title'].iloc[0]\n",
        "      i+=1\n",
        "    similar_df=pd.DataFrame(\n",
        "    {'show_id': similar_ids,\n",
        "    'title': similar_titles,\n",
        "    'similarity': similarities\n",
        "    })\n",
        "    similar_df.index = range(1, len(similar_df)+1)\n",
        "\n",
        "    return similar_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o4MyA5V2etp"
      },
      "source": [
        "Indicative results :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evn5AueU2f28"
      },
      "outputs": [],
      "source": [
        "description_test=\"Accompanied by a German bounty hunter, a freed slave named Django travels across America to free his wife from a sadistic plantation owner.\"\n",
        "\n",
        "print(\"Django Unchained\")\n",
        "print(\"Boolean method:\")\n",
        "display(get_similar_movies2(description_test, 20, 'boolean'))\n",
        "print(\"TF-IDF method:\")\n",
        "display(get_similar_movies2(description_test, 20, 'tf-idf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuvYqNXH2gRA"
      },
      "source": [
        "Η συνάρτηση δημιουργεί ένα feature vector για το description που δίνεται.\n",
        "Μετά το διαμορφώνει ώστε τα terms του να είναι τα ίδια με αυτά του vocabulary(αν κάποιο term υπάρχει στο vocabulary του description αλλά όχι στων ταινιών τότε απορρίπτεται).\n",
        " \n",
        "Η περιγραφή που περνιέται σαν όρισμα είναι αυτή της ταινίας \"Django Unchained\".\n",
        " \n",
        "Η boolean μέθοδος βγάζει ακριβώς τα ίδια αποτελέσματα(και similarity 1.0 με την ταινία που έχει το ίδιο description), αφού ο boolean BoW πίνακας δείχνει απλά αν ένα term υπάρχει στο description ή όχι οπότε δεν υπάρχει κάποια διαφορά με το να φτιαχτεί με τα υπόλοιπα descriptions η ξεχωριστά(αν όλα τα terms του description υπάρχουν στο vocabulary).\n",
        " \n",
        "Η tf-idf μέθοδος έχει μια απόκλιση αφού ο πίνακας δημιουργήθηκε μόνο για αυτό το description (ξεχωριστά από τα descriptions), οπότε δεν μπορεί να υπολογιστεί σωστά το idf. Έτσι υπάρχουν τίτλοι διαφορετικοί,με διαφορετικό similarity score η σε διαφορετική σειρά.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Project-1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.6.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "58bc13ec4dd135858b8220102d0ad3358f57eb64d131366ec25c4d4365eacf63"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
